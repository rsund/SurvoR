SURVO84ED 81 200    81 S20                                                       *SAVE EDQM10                                                                     *LOAD EDQ                                                                        *                                                                                *MARKOV?                                                                         *                                                                                S Operating with Markov chains in Survo                                          *                                                                                *   1 = Generating Markov chains by Shannon's technique (MARKOV)                 *   2 = Steady-state probabilities of an irreducible chain (/MARKOV-STEADY)      *   3 = Generating Markov chains by TRANSFORM                                    *   4 = Structure of the chain and steady-state probabilities (MARKOV STUDY)     *   5 = Computing transition probabilities between 2 given states (MARKOV PROB) C*   6 = Generating and working with Markov chains of higher order               C*                                                                                *   M = More information on mathematical operations                              *                                                                                %1=MARKOV1 2=MARKOV2 3=MARKOVD? 4=MARKOV4 5=MARKOV5 6=MARKOVH M=MATH?            *                                                                                *MARKOV1?                                                                        *MARKOV L1,L2,L / ORDER=<integer>                                                *simulates the behaviour of a Markov chain by a method presented by              *Claude Shannon. The states are symbols (digits, letters, etc.)                  *and a sample of the chain is given as a stream of such characters               *on edit lines L1-L2. The simulated results generated according to               *this sample are listed as a new stream of characters from line L                *onwards. The order of the Markov chain is given by the ORDER                    *specification. Default is ORDER=1.                                              *                                                                                *Another alternatives are offered by certain spcial forms of the                 *TRANSFORM operation (See MARKOVD?)                                              *@GOTO M                                                                         *                                                                                *M?                                                                              *                                                                                *   M = More information on Markov chains                                        %M=MARKOV                                                                        *                                                                                *MARKOV2?                                                                        */MARKOV-STEADY P                                                                *computes the steady-state probabilities of an irreducible Markov chain          *by direct solution of the homogeneous system of linear equations.               *This works only for irreducible chains.                                         *The transition probabilities P must be given as (square) matrix file            *P and the steady-state probabilities will be saved in a matrix file             *PI.M                                                                            *@GOTO M                                                                         *                                                                                *MARKOV4?                                                                        *MARKOV STUDY P,L                                                                *where P is a matrix file of transition probabilities determines the             *class structure of the Markov chain and gives the results from the              *edit line L onwards as shown in the following example:                          *MATRIX P                                                                        *///  T1  T2  T3  T4  T5                                                         *T1   0.4 0   0   0   0.6                                                        *T2   0.9 0   0   0.1 0                                                          *T3   0   0   0.2 0.8 0                                                          *T4   0   0   0.8 0.2 0                                                          *T5   0.7 0   0   0   0.3                                                        *                                                                                *MAT SAVE P                                                                      *MARKOV STUDY P,CUR+1                                                            *Structure of Markov chain P of 5 states:                                        *Class structure saved in matrix file MCLASS.M                                   *2 recurrent classes of states:                                                  *1 (2): T1 T5                                                                    *2 (2): T3 T4                                                                    *1 transient state:                                                              * T2                                                                             *@C                                                                              *By default the results are obtained by finding the transitive closure           *of the digraph determined by P.                                                 *By using the specification SVD=1 the same task is accomplished by               *computing the singular value decomposition of I-P. Then also the                *steady-state probabilities for each recurrent classes are calculated            *and given as the second column of matrix MCLASS.M                               *In the above example this gives                                                 *                                                                                *LOADM MCLASS.M,(C7),CUR+1                                                       *Class_structure_of_P_(Transient_states=0)                                       *           Class    Prob                                                        *T1             1 0.53846                                                        *T2             0 0.00000                                                        *T3             2 0.50000                                                        *T4             2 0.50000                                                        *T5             1 0.46154                                                        *                                                                                *@GOTO M                                                                         *                                                                                *MARKOV5?                                                                        @MARKOV PROB P,i,j,n,PN                                                          *from a transition probability matrix P of a Markov chain                        *computes k-step transition probabilities from state i to j                      *for k=1,2,...,n and saves them as a new vector PN.                              *@GOTO M                                                                         *                                                                                *MARKOVH?                                                                        *                                                                                S Operating with Markov chains of higher order                                   *                                                                                *   1 = Generating Markov chains of order 1,2,3,...                              *   2 = Estimating transition probabilities from a given sample                  *                                                                                *   M = More information on Markov chains                                        *                                                                                %1=MARKOVH1 2=MARKOVH2 M=MARKOV                                                  *                                                                                *MARKOVH1?                                                                       *Generating Markov chains of order 1,2,3,...                                     *                                                                                *When the matrix of transition probabilities is given as a Survo matrix file,    *samples of the chain may be generated                                           *                                                                                *either by the MARKOV command of the form                                        *MARKOV L1,L2 BY P                                                               *where P is the transition matrix and L1 is the first line and L2 the            *last line for the generated sequence (see example on the next page)             *                                                                                *or by a special form of the TRANSFORM operation (see MARKOVD?).                 *                                                                                *The following tutorial shows more examples:                                     */MARKOV-DEMO2                                                                   >EDQ-MARKOV2 /                             Activate the demo by |EXAMPLE|       C*@C                                                                              *Generating a Markov chain of order 3 with two states A,B:                       *MATRIX P82                                                                      *///   A    B                                                                    *AAA   0    1                                                                    *AAB   0.5  0.5                                                                  *ABA   0.3  0.7                                                                  *ABB   0.9  0.1                                                                  *BAA   0    1                                                                    *BAB   0.5  0.5                                                                  *BBA   0.2  0.8                                                                  *BBB   0.1  0.9                                                                  *                                                                                *MAT SAVE P82 / Saving the matrix of transition probabilities                    *MARKOV CUR+1,CUR+5 BY P82 / Generate a sample to next 5 lines!                  *BABABABABBAABBABABBABBABABAABBBBBBBBBBBBBBBBBBBBBBBBBBBBBABAABBAABABBAA         *BBABBABBABAABBABBABBABABBAABABBABABAABBABBABABABABAABABAABABABABABABBBB         *BBBBBBAABABABBABAABBABAABBAABBAABABBABBABABABBBBBBBBBBBBABBABAABAABBABB         *BBBBBBBBBBBBABBAABABBABBAABBABABABAABBABABABABBABBABAABBAABAABAABABABAA         *BABBABBAABBABBABABBAABBABBABBABABABAABABBABABBABBABBABAABAABAABBABBABBA         *@GOTO MH                                                                        *                                                                                *MH?                                                                             *                                                                                *   H = More information on Markov chains of higher order                        %H=MARKOVH                                                                       *                                                                                *MARKOVH2?                                                                       *Estimating transition probabilities from a given sample                         *                                                                                *MARKOV L1,L2 / MATRIX=<matrix> STATES=<list_of_states> ORDER=<integer>          *estimates <matrix> of transition probabilities on the basis of a sample         *sequence of one-character state names on edit lines L1-L2.                      *The STATES specification tells the list of the state names.                     *                                                                                *An example of this operation is found in the tutorial                           */MARKOV-DEMO2                                                                   >EDQ-MARKOV2 /                             Activate the demo by |EXAMPLE|       C*@GOTO MH                                                                        *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                Shadows                                                                            ///////////////////////////////////////                                       c  //////////////////////////////////////////////                                END                                                                              