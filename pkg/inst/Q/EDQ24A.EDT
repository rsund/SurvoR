SURVO84ED 81 240    81 S20                                                       *SAVE EDQ24A                                                                     *                                                                                *AR?                                                                             *Estimating AR(p) models by ESTIMATE                                            C*                                                                                *The AR(p) model is                                                              *(1) Y = X*beta + u                                                              *where Y is an n-vector of dependent variable, X is an n*m-matrix of             *regressors, beta is an m-vector of regression coefficients and                  *u = (u(1),u(2),...,u(n))' are residuals of the form                             *                                                                                *u(j)=r(1)*u(j-1)+...+r(p)*u(j-p)+e(j)                                           *                                                                                *where e(j), j=1,2,...,n are independent N(0,sigma^2) variables.                 *                                                                                *The easiest method for estimation of beta and r(1),...,r(p)                     *is to estimate the nonlinear regression model (please note that u=Y-X*beta)     *                         p                                                      *(2) y(j) = x(j)*beta +  sum r(i)*[y(j-i)-x(j-i)*beta]  + e(j),                  *                        i=1                                                     *                                               j=p+1,2,...,n,                   *where x(j) is a row vector of regressors x1,x2,...,xm in the j'th               *observation.                                                                    *@C                                                                              *Least squares estimates for the model (2) are obtained by the ESTIMATE          *operation as follows (the scheme is here presented for p=3 in a case            *where we have Y as the regressand and X1,X2,X3,X4 as regressors).               *.......................................................................         a{A0}=b0+b1*X1+b2*X2+b3*X3+b4*X4                                                 a{A1}=r1*(Y[-1]-b0-b1*X1[-1]-b2*X2[-1]-b3*X3[-1]-b4*X4[-1])                      a{A2}=r2*(Y[-2]-b0-b1*X1[-2]-b2*X2[-2]-b3*X3[-2]-b4*X4[-2])                      a{A3}=r3*(Y[-3]-b0-b1*X1[-3]-b2*X2[-3]-b3*X3[-3]-b4*X4[-3])                      *                                                                                *MODEL AR3                                                                       aY={A0}+{A1}+{A2}+{A3}                                                           *                                                                                *ESTIMATE <data>,AR3,<line_for_results>                                          *.......................................................................         *ESTIMATE automatically recognizes the observed variables Y,X1,X2,X3,X4          *from the data and interprets unidentified notations                             *b0,b1,b2,b3,b4 and r1,r2,r3 as parameters to be estimated.                      *@C                                                                              *The components of the model are presented by shorthand notations                a{A0},{A1},... permitting a brief notation for the model itself.                 *Lagged values are notated as Y[-2] (Y lagged by 2) as in the VAR operation.     aIt is easy to extend the model for larger p and even drop some {Ai}             *components.                                                                     *Good starting values for b's are obtained from OLS estimates (LINREG,           aREGDIAG, or ESTIMATE with model Y={A0}).                                        *                                                                                *Since ARMA(p,q) models can be represented as A(infinity), in many cases         *the regression coefficients may be estimated for such more general              *models from AR(p) when p is large enough.                                       *                                                                                >HELP-ARP /                                                 See |EXAMPLE|       C*  1 = More information about ESTIMATE operation                                 *                                                                                %1=ESTIMATE?                                                                     *@SELECT                                                                         *                                                                                *ARMA?                                                                           *Estimating ARMAX(p,q) models by ESTIMATE                                       C*                                                                                *A general ARMAX(p,q) model is                                                   *                                                                                *(1) Y = X*beta + u,                                                             *                                                                                *where Y    is an n vector of regressand,                                        *      X    is an n*m matrix of m regressors,                                    *      beta is m vector of regression coefficients,                              *      u    is an n vector of residuals u(1),...,u(n)                            *and the residual u(j) related to the j'th observation depends on                *p preceding residuals u(j-1),...,u(j-p) and q independent                       *N(0,s^2) error terms e(j),e(j-1),...,e(j-q) as follows                          *                                                                                *(2) u(j)=r(1)*u(j-1)+...+r(p)*u(j-p)+e(j)+a(1)*e(j-1)+...+a(q)*e(j-q),          *                                                                                *where r(1),...,r(p) and a(1),...,a(q) are unknown parameters.                   *                                                                                *In fact, also non-linear models, where X*beta (the part of exogenous            *variables) is replaced by a more general function f(x,beta), may be             *estimated by the following method.                                              *@C                                                                              *A conditional maximum likelihood method (see e.g. Hamilton: Time Series         *Analysis, 1994, Chapter 5.6) will be applied.                                   *The conditional log likelihood function (with respect to first                  *observations and error terms) is a sum of expressions                           *                                                                                *(3) -0.5*(log(s^2)+e(j)^2/s^2+log(2*pi))                                        *                                                                                *where e(j)'s are determined by (2) and u(j)'s are obtained from (1).            *                                                                                *Since e(j) depends on previous values e(j-1),...,e(j-q),                        *during the estimation process the values of e variable                          *have to be updated always when values of parameters to be estimated             *s,beta,r(1),...,r(p),a(1),...,a(q) are changed.                                 *                                                                                *To provide this feature in ESTIMATE, an extra variable (say EPS)                *must be defined in the original data set with initial values 0.                 *Updating of e values is imposed by an UPDATE specification.                     *The final values of e will be saved in the data set after the                   *estimation.                                                                     *@C                                                                              *For example, in the model                                                       *Y=b0+b1*X1+b2*X2+b3*X3+b4*X4+u,                                                 *where u has the ARMA(3,1) structure, the ESTIMATE scheme is written             *as follows:                                                                     *- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -                   a11 *{A0}=Y-b0-b1*X1-b2*X2-b3*X3-b4*X4                                           a12 *{AR1}=r1*(Y[-1]-b0-b1*X1[-1]-b2*X2[-1]-b3*X3[-1]-b4*X4[-1])                 a13 *{AR2}=r2*(Y[-2]-b0-b1*X1[-2]-b2*X2[-2]-b3*X3[-2]-b4*X4[-2])                 a14 *{AR3}=r3*(Y[-3]-b0-b1*X1[-3]-b2*X2[-3]-b3*X3[-3]-b4*X4[-3])                 a15 *{EPS}={A0}-{AR1}-{AR2}-{AR3}-a1*EPS[-1]                                     *16 *UPDATE=EPS                                                                  *17 *                                                                            *18 *MODEL ARMA                                                                  a19 *LOGDENSITY=-0.5*(log(s*s)+({EPS})^2/(s*s))                                  *20 *                                                                            *21 *ESTIMATE <data>,ARMA,CUR+1                                                  *22 *                                                                            *- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -                   *The model ARMA (lines 18-19) is defined according to (3) and                    athe {EPS} expression, e(j) solved from (2), is given on line 15.                *Various components of the model (in braces) are on lines 11-14.                 *@C                                                                              *The specification UPDATE=EPS quarantees that ESTIMATE will update               aEPS according to expression {EPS} (line 15) and saves the final values          *as variable EPS.                                                                *UPDATE admits even a list of variables which may be useful in more              *general models.                                                                 *                                                                                *Because the likelihood function has typically many local maxima,                *one has to be careful when selecting initial values for parameters.             *Good values for s and beta may be obtained from OLS estimation                  *(by LINREG or REGDIAG).                                                         *Initial values for ARMA parameters may be found by making a grid search         *(METHOD=G in ESTIMATE).                                                         *                                                                                >HELP-ARMA /                                                See |EXAMPLE|       C*  1 = More information about ESTIMATE operation                                 *                                                                                %1=ESTIMATE?                                                                     *@SELECT                                                                         *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                *                                                                                END                                                                              